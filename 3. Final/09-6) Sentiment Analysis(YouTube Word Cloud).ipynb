{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05997562-778f-485b-a4b6-1f722a40d89a",
   "metadata": {},
   "source": [
    "# **Sentiment Analysis(Preprocessing)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a460604-5bbd-4b6e-94fc-426305c04937",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "### Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "### DB 연결\n",
    "# !pip install pymysql\n",
    "import pymysql\n",
    "\n",
    "### DB에 저장\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "### 실시간 주식가격 데이터\n",
    "# !pip install finance-datareader\n",
    "import FinanceDataReader as fdr\n",
    "\n",
    "### 텍스트 분석\n",
    "## KoNLPy\n",
    "# 1) JAVA 설치, 2) Python 버전과 맞는 JPype1-py3 설치, 3) !pip install konlpy, 4) 설치 경로에서 jvm.py 파일 코드 67번 줄 주석 처리 \n",
    "from konlpy.tag import Okt\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import re\n",
    "## FastText\n",
    "# !pip install gensim\n",
    "# !pip install fasttext\n",
    "import fasttext\n",
    "import fasttext.util\n",
    "# Facebook 한국어 Embedding 모델 다운로드 → 한 번만 설치하면 됨\n",
    "# fasttext.util.download_model('ko', if_exists='ignore')   # FastText 모델 사용 시에만 필요\n",
    "# 유사도 계산\n",
    "from gensim import models\n",
    "\n",
    "### 모델 학습 및 평가\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "### 모델 저장 및 로드\n",
    "import joblib\n",
    "\n",
    "### 기타\n",
    "import datetime\n",
    "from collections import Counter\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c9a66e-91d4-4f6d-8415-6abfac14f8fe",
   "metadata": {},
   "source": [
    "## **Develop Full Step Program**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a585cef-e9eb-46e7-84c4-65ff98533069",
   "metadata": {},
   "source": [
    "### **① Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20a211c4-1d38-48b9-94b6-da44114896fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def arguments(x):\n",
    "    \n",
    "    \n",
    "    ### 1) 매체 선택\n",
    "    media_list = ['삼프로TV', '슈카월드', '한국경제TV']\n",
    "    media_name = x\n",
    "    while media_name not in media_list:\n",
    "        media_name = x\n",
    "        if media_name in media_list:\n",
    "            break\n",
    "    if media_name == '삼프로TV':\n",
    "        globals()['craw_media'] = 'youtube_sampro'\n",
    "    elif media_name == '슈카월드':\n",
    "        globals()['craw_media'] = 'youtube_suka'\n",
    "    else:\n",
    "        globals()['craw_media'] = 'youtube_hk'\n",
    "    \n",
    "    \n",
    "    ### 2) date 지정\n",
    "    \n",
    "    ## 2-1) 시작 날짜\n",
    "    globals()['start_date'] = (datetime.datetime.now() - datetime.timedelta(10)).strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    ## 2-2) 종료 날짜\n",
    "    globals()['end_date'] = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    \n",
    "    return globals()['craw_media'], globals()['start_date'], globals()['end_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef174903-b953-4556-8bed-d2b5c1aed99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#*** 아직 YouTube 채널 크롤링 데이터는 별도의 전처리 코드 작성 필요 ***#\n",
    "def media_stock_prediction(craw_media, start_date, end_date):\n",
    "    #### 1. Read Data\n",
    "    \n",
    "    \n",
    "    ### 1) KOSELF 감성 어휘 사전\n",
    "    #*** 추후에 감성사전도 DB 연결해서 사용하도록 코드 변경 필요 ***#\n",
    "    with open('KOSELF_pos.txt', encoding='utf-8') as pos:\n",
    "        positive = pos.readlines()\n",
    "    positive = [pos.replace('\\n', '') for pos in positive]\n",
    "    with open('KOSELF_neg.txt', encoding='utf-8') as neg:\n",
    "        negative = neg.readlines()\n",
    "    negative = [neg.replace('\\n', '') for neg in negative]\n",
    "    \n",
    "    \n",
    "    ### 2) News Data from DB\n",
    "    db = pymysql.connect(user='root',\n",
    "                         passwd='1234',\n",
    "                         host='3.35.70.166',\n",
    "                         db='proj',\n",
    "                         charset='utf8')\n",
    "    \n",
    "    cursor = db.cursor(pymysql.cursors.DictCursor)\n",
    "    \n",
    "    ## 2-1) 전체 종목 뉴스 데이터\n",
    "    corp_list = ['samsung', 'hyundai', 'lg', 'sk', 'celltrion']\n",
    "    stock_num_list = ['005930', '005380', '051910', '000660', '068270']\n",
    "    \n",
    "    ## 2-2) DB의 date 컬럼과 형태 통일\n",
    "    globals()['start_date'] = globals()['start_date'].replace('-', '')\n",
    "    globals()['end_date'] = globals()['end_date'].replace('-', '')\n",
    "    for i in range(len(corp_list)):\n",
    "        sql = \"select * from {0}_{1} where (length(date)=10) and (date between {2}00 and {3}23)\".format(globals()['craw_media'], stock_num_list[i], globals()['start_date'], globals()['end_date'])\n",
    "        cursor.execute(sql)\n",
    "        result = cursor.fetchall()\n",
    "\n",
    "        # DataFrame으로 변경\n",
    "        globals()[corp_list[i]] = pd.DataFrame(result)\n",
    "    \n",
    "    db.close()   # 메모리 절약\n",
    "    \n",
    "    ## 2-3) 날짜와 시간 구분\n",
    "    for i in range(len(corp_list)):\n",
    "        globals()[corp_list[i]].rename(columns={'date': 'datetime'}, inplace=True)\n",
    "\n",
    "        # DataFrame 형태를 통일하기 위해 date 컬럼 추가\n",
    "        globals()[corp_list[i]]['date'] = globals()[corp_list[i]]['datetime'].str[0:4] + '-' + globals()[corp_list[i]]['datetime'].str[4:6] + '-' + globals()[corp_list[i]]['datetime'].str[6:8]\n",
    "        globals()[corp_list[i]]['date'] = pd.to_datetime(globals()[corp_list[i]]['date'])\n",
    "\n",
    "        # 결측치 제거 → 데이터 로드 시 완료했기 때문에 그다지 필요하지 않은 과정\n",
    "        globals()[corp_list[i]] = globals()[corp_list[i]].dropna()\n",
    "\n",
    "        # 시간순으로 정렬\n",
    "        globals()[corp_list[i]].sort_values('datetime', inplace=True)\n",
    "        globals()[corp_list[i]].reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    \n",
    "    ### 3) FinanceDataReader\n",
    "    # 종료 날짜는 현재 시각을 기준으로\n",
    "    end_date = datetime.datetime.now().strftime(\"%Y%m%d\")\n",
    "    for i in range(len(corp_list)):\n",
    "        globals()['stock_' + corp_list[i]] = fdr.DataReader(stock_num_list[i], start=start_date, end=end_date).reset_index()\n",
    "    \n",
    "    \n",
    "    ### 4) Holidays\n",
    "    db = pymysql.connect(user='root',\n",
    "                         passwd='1234',\n",
    "                         host='3.35.70.166',\n",
    "                         db='proj',\n",
    "                         charset='utf8')\n",
    "\n",
    "    cursor = db.cursor(pymysql.cursors.DictCursor)\n",
    "\n",
    "    # 4-1) 주말 및 공휴일 데이터\n",
    "    sql = \"select * from holidays\"\n",
    "    cursor.execute(sql)\n",
    "    result = cursor.fetchall()\n",
    "    \n",
    "    # DataFrame으로 변경\n",
    "    globals()['holidays'] = pd.DataFrame(result)\n",
    "    \n",
    "    db.close()   # 메모리 절약\n",
    "    \n",
    "    # 4-2) date 컬럼을 날짜 형식으로 변경\n",
    "    globals()['holidays']['date'] = pd.to_datetime(holidays['date'])\n",
    "    \n",
    "    \n",
    "    ### 5) Stop Words\n",
    "#     #*** 추후에 Stop Words도 DB 연결해서 사용하도록 코드 변경 필요 ***#\n",
    "#     with open('stopwords-ko.txt', encoding='utf-8') as sw:\n",
    "#         globals()['stop_words'] = sw.readlines()\n",
    "#     globals()['stop_words'] = [sw.replace('\\n', '') for sw in stop_words]\n",
    "    # GitHub로부터 Stop Words 로드\n",
    "    stopwords = pd.read_csv(\"https://raw.githubusercontent.com/yoonkt200/FastCampusDataset/master/korean_stopwords.txt\")\n",
    "    # Stop Words List에 각 매체명 추가\n",
    "    except_media_list = ['매일경제', '매일', '경제', 'maeil', 'MK', 'mk',\n",
    "                         '아시아경제', '아시아', 'Asia', 'ASIA', 'asia',\n",
    "                         '삼프로TV', '삼프로', 'TV',\n",
    "                         '슈카월드', '슈카', '월드'\n",
    "                         '한국경제TV', '한국']\n",
    "    for word in [except_media_list]:\n",
    "        stopwords.append(word)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #### 2. Preprocessing\n",
    "    '''감성 어휘 사전 : negative / positive\n",
    "       뉴스 데이터 : samsung / hyundai / lg / sk\n",
    "       주식 데이터 : stock_samsung / stock_hyundai / stock_lg / stock_sk\n",
    "       공휴일 데이터 : holidays'''\n",
    "    \n",
    "    \n",
    "    ### 1) 뉴스 데이터 날짜 조정\n",
    "    \n",
    "    ## 1-1)업로드 시각 컬럼 추가\n",
    "    for i in range(len(corp_list)):\n",
    "        globals()[corp_list[i]]['time'] = globals()[corp_list[i]]['datetime'].str[-2:]\n",
    "    \n",
    "    ## 1-2) 전일 15시 ~ 금일 15시로 날짜 조정\n",
    "    after_market = ['15', '16', '17', '18', '19', '20', '21', '22', '23']\n",
    "\n",
    "    for i in range(len(corp_list)):\n",
    "        for j in range(len(globals()[corp_list[i]]['time'])):\n",
    "            if globals()[corp_list[i]]['time'][j] in after_market:\n",
    "                globals()[corp_list[i]]['date'][j] += datetime.timedelta(1)\n",
    "            else:\n",
    "                pass\n",
    "    \n",
    "    ## 1-3) 텍스트 전처리\n",
    "    # \\n, \\t, \\r 제거\n",
    "    for i in range(len(corp_list)):\n",
    "        for j in range(len(globals()[corp_list[i]]['text'])):\n",
    "            globals()[corp_list[i]]['text'][j] = globals()[corp_list[i]]['text'][j].replace('[\\n|\\t|\\r]', '')\n",
    "#     # text 컬럼의 Stop Words 제거\n",
    "#     for i in range(len(corp_list)):\n",
    "#         globals()[corp_list[i]]['except_stopwords'] = 0\n",
    "#         for j in range(len(globals()[corp_list[i]]['text'])):            \n",
    "#             hangeul = re.compile('[^ ㄱ-ㅣ 가-힣]')                         # 정규 표현식  → 한글 추출 규칙 : 띄어쓰기(1개)를 포함한 한글\n",
    "#             result = hangeul.sub('', globals()[corp_list[i]]['text'][j])   # 위에 설정한 hangeul 규칙을 text에 적용\n",
    "#             okt = Okt()                                                    # 형태소 추출\n",
    "#             nouns = okt.nouns(result)\n",
    "#             nouns = [x for x in nouns if len(x) > 1]                       # 한 글자 키워드 제거\n",
    "#             nouns = [x for x in nouns if x not in stopwords]               # 불용어 제거\n",
    "            \n",
    "#             corpus = \" \".join(nouns)                                       # List를 String으로 변환\n",
    "#             globals()[corp_list[i]]['except_stopwords'][j] = corpus\n",
    "    \n",
    "        \n",
    "    ### 2) 주말 및 공휴일 제외\n",
    "    \n",
    "    ## 2-1) 주말 및 공휴일만 추출\n",
    "    market_closed = globals()['holidays'][globals()['holidays']['holiday']==\"O\"].reset_index(drop=True)\n",
    "    \n",
    "    ## 2-3) 휴장일 List 생성\n",
    "    market_closed_list = list(market_closed['date'])\n",
    "    \n",
    "    ## 2-4) iteration limit 조정\n",
    "    limit_number = 15000\n",
    "    sys.setrecursionlimit(limit_number)\n",
    "    \n",
    "    ## 2-5) 휴장일 제외 함수 적용\n",
    "    # 주말 및 공휴일 제외 함수\n",
    "#     def stock_market_closed(df):\n",
    "#         for i in range(len(df['date'])):\n",
    "#             if df['date'][i] in market_closed_list:\n",
    "#                 df['date'][i] += datetime.timedelta(1)\n",
    "#                 stock_market_closed(df)\n",
    "#             else:\n",
    "#                 pass\n",
    "#         return df\n",
    "    \n",
    "#     for i in range(len(corp_list)):\n",
    "#         stock_market_closed(globals()[corp_list[i]])\n",
    "    for i in range(len(corp_list)):\n",
    "        while len(globals()[corp_list[i]][globals()[corp_list[i]]['date'].isin(market_closed_list)]['date']) != 0:\n",
    "            for j in globals()[corp_list[i]][globals()[corp_list[i]]['date'].isin(market_closed_list)]['date'].index:\n",
    "                globals()[corp_list[i]]['date'][j] += datetime.timedelta(1)\n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "    #### 3. Sentiment Analysis\n",
    "    \n",
    "    \n",
    "#     ### 1) 종목별 긍부정 Score 계산\n",
    "#     for i in range(len(corp_list)):\n",
    "#         globals()[corp_list[i]]['score'] = 0\n",
    "#         tokenizer = Okt()\n",
    "\n",
    "#         for x in range(len(globals()[corp_list[i]]['date'])):\n",
    "#             score = 0\n",
    "#             num = tokenizer.nouns(globals()[corp_list[i]]['text'][x])\n",
    "#             for y in num:\n",
    "#                 # KOSELF 감성 어휘 사전\n",
    "#                 if y in positive:\n",
    "#                     score += 1\n",
    "#                 elif y in negative:\n",
    "#                     score -= 1\n",
    "#                 else:\n",
    "#                     score = score\n",
    "\n",
    "#             globals()[corp_list[i]]['score'][x] = score\n",
    "    \n",
    "    \n",
    "    ### 2) 주식가격 데이터와 결합\n",
    "    corp_label_list = []\n",
    "    for i in range(len(corp_list)):\n",
    "        \n",
    "        ## 2-1) 결합\n",
    "        globals()[corp_list[i] + '_label'] = pd.merge(globals()[corp_list[i]], globals()['stock_' + corp_list[i]], how='left', left_on='date', right_on='Date')\n",
    "        globals()[corp_list[i] + '_label'].drop('Date', axis=1, inplace=True)\n",
    "        \n",
    "        ## 2-2) UpDown과 Extremely_Changed(Change 상하위 5%) 컬럼 생성\n",
    "#         # 주식 매매 수수료 평균 : 0.1% 정도(?) → 0을 추가해도 1, -1만 나옴\n",
    "#         globals()[corp_list[i] + '_label']['UpDown'] = np.where((globals()[corp_list[i] + '_label']['Close']*globals()[corp_list[i] + '_label']['Change'])>(globals()[corp_list[i] + '_label']['Close']*0.001), 1,\n",
    "#                                                                 np.where((globals()[corp_list[i] + '_label']['Close']*globals()[corp_list[i] + '_label']['Change'])<(globals()[corp_list[i] + '_label']['Close']*0.001), -1, 0))\n",
    "        globals()[corp_list[i] + '_label']['UpDown'] = np.where(globals()[corp_list[i] + '_label']['Change']<0, -1,\n",
    "                                                                np.where(globals()[corp_list[i] + '_label']['Change']>0, 1, 0))\n",
    "#         # 단순히 Change가 (+), 0, (-)인지에 따라 각각 1, 0, -1\n",
    "#         globals()[corp_list[i] + '_label']['UpDown'] = np.where(globals()[corp_list[i] + '_label']['Change']>0, 1,\n",
    "#                                                                 np.where(globals()[corp_list[i] + '_label']['Change']<0, -1, 0))\n",
    "#         globals()[corp_list[i] + '_label']['Extremely_Changed'] = np.where((globals()[corp_list[i] + '_label']['Change']>globals()[corp_list[i] + '_label']['Change'].quantile(.95)) & (globals()[corp_list[i] + '_label']['Change']>0), 1,\n",
    "#                                                                            np.where((globals()[corp_list[i] + '_label']['Change']<globals()[corp_list[i] + '_label']['Change'].quantile(.05)) & (globals()[corp_list[i] + '_label']['Change']<0), -1, 0))\n",
    "        \n",
    "        ## 2-3) List에 추가\n",
    "        corp_label_list.append(globals()[corp_list[i] + '_label'])\n",
    "        \n",
    "        ## 2-4) text 컬럼의 NaN 제거\n",
    "        globals()[corp_list[i] + '_label'].dropna(axis=0, inplace=True)\n",
    "    \n",
    "    \n",
    "    ### 3) Tokenization 컬럼 추가\n",
    "    globals()['corp_list_label'] = []\n",
    "    for i in range(len(corp_list)):\n",
    "        globals()[corp_list[i] + '_label']['Tokenization'] = 0\n",
    "        rows = globals()[corp_list[i] + '_label'].shape[0]\n",
    "        for j in range(rows):\n",
    "            hangeul = re.compile('[^ ㄱ-ㅣ 가-힣]')                                    # 정규 표현식 → 한글 추출 규칙 : 띄어쓰기(1개)를 포함한 한글\n",
    "            result = hangeul.sub('', globals()[corp_list[i] + '_label']['text'][j])   # 위에 설정한 hangeul 규칙을 text에 적용\n",
    "            okt = Okt()                                                               # 형태소 추출\n",
    "            nouns = okt.nouns(globals()[corp_list[i] + '_label']['text'][j])\n",
    "            nouns = [x for x in nouns if len(x) > 1]                                  # 한 글자 키워드 제거\n",
    "            nouns = [x for x in nouns if x not in stopwords]                          # 불용어 제거\n",
    "            \n",
    "            corpus = \" \".join(nouns)                                                  # List를 String으로 변환\n",
    "            globals()[corp_list[i] + '_label']['Tokenization'][j] = corpus\n",
    "        globals()['corp_list_label'].append(globals()[corp_list[i] + '_label'])\n",
    "        \n",
    "    \n",
    "    ### 4) 전체 종목 DataFrame 통합\n",
    "    globals()['total_label'] = pd.concat(corp_label_list, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40b8f44-3dcb-40e3-be10-645bcb09470f",
   "metadata": {},
   "source": [
    "### **② Sentiment Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "175f84a9-f759-46e5-94bc-b246486aeaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 블로그에서 가져온 기본적인 한국어 긍부정 텍스트 목록\n",
    "with open('positive_words_self.txt', encoding='utf-8') as pos_blog:\n",
    "    positive_blog = pos_blog.readlines()\n",
    "positive_blog = [pos_blog.replace('\\n', '') for pos_blog in positive_blog]\n",
    "with open('negative_words_self.txt', encoding='utf-8') as neg_blog:\n",
    "    negative_blog = neg_blog.readlines()\n",
    "negative_blog = [neg_blog.replace('\\n', '') for neg_blog in negative_blog]\n",
    "\n",
    "# KOSELF 감성 어휘 사전\n",
    "with open('KOSELF_pos.txt', encoding='utf-8') as pos:\n",
    "    positive = pos.readlines()\n",
    "positive = [pos.replace('\\n', '') for pos in positive]\n",
    "with open('KOSELF_neg.txt', encoding='utf-8') as neg:\n",
    "    negative = neg.readlines()\n",
    "negative = [neg.replace('\\n', '') for neg in negative]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22812bfa-0e87-424c-88ec-ca252ab85f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 긍정사전 통합\n",
    "for i in range(len(positive_blog)):\n",
    "    if positive_blog[i] not in positive:\n",
    "        positive.append(positive_blog[i])\n",
    "\n",
    "# 부정사전 통합\n",
    "for i in range(len(negative_blog)):\n",
    "    if negative_blog[i] not in negative:\n",
    "        negative.append(negative_blog[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5db29d9c-d88b-4c83-aab1-259278573cf2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'datetime'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\multi\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3079\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3080\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'datetime'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-51416ca1d12a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmedia_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0marguments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmedia_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mmedia_stock_prediction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglobals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'craw_media'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglobals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'start_date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglobals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'end_date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mglobals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'total_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-1f29cab9d479>\u001b[0m in \u001b[0;36mmedia_stock_prediction\u001b[1;34m(craw_media, start_date, end_date)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[1;31m# DataFrame 형태를 통일하기 위해 date 컬럼 추가\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[0mglobals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcorp_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mglobals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcorp_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'datetime'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'-'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mglobals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcorp_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'datetime'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'-'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mglobals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcorp_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'datetime'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m         \u001b[0mglobals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcorp_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglobals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcorp_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\multi\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3022\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3023\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3024\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3025\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\multi\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3080\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3082\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3084\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'datetime'"
     ]
    }
   ],
   "source": [
    "media_list = ['삼프로TV', '슈카월드', '한국경제TV']\n",
    "corp_list = ['samsung', 'hyundai', 'lg', 'sk', 'celltrion']\n",
    "\n",
    "globals()['total_youtube'] = []\n",
    "for i in range(len(media_list)):\n",
    "    arguments(media_list[i])\n",
    "    media_stock_prediction(globals()['craw_media'], globals()['start_date'], globals()['end_date'])\n",
    "    globals()['total_' + str(i)] = []\n",
    "    \n",
    "    for j in range(len(corp_list)):\n",
    "        globals()['total_' + str(i)].append(globals()[corp_list[j] + '_label'])\n",
    "    \n",
    "    globals()['total_youtube'].append(globals()['total_' + str(i)])\n",
    "\n",
    "total = pd.concat(globals()['total_youtube'], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e47b8c-84ca-4c09-95d1-55cd69eddaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "globals()['total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc3470e-abbd-442c-97df-0e33c403c975",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086d9a1d-c678-415a-8eaf-b5e3984d332c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a51be5-a3ee-4db4-b32d-0aead995690d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8bb48d-62a4-409a-bc19-dd39941820b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a177dde-d226-457e-8143-d5aa9697ac7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e90e614-34b1-495f-a9dd-b8618d6d46cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253afba4-9e8d-4e71-8307-a374350e414c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 종목별 데이터 통합\n",
    "corp_list = ['samsung', 'hyundai', 'lg', 'sk', 'celltrion']\n",
    "\n",
    "total = pd.concat(globals()['corp_list_label'], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1362a0-1186-43e5-8b0a-f503e283a25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fb1604-5fa8-4946-bf58-99e735f1fcdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be6585a-ba1f-48e8-b602-bcee5ea4eda6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d072ca13-82b6-4ad9-84ce-f59a1b6f3573",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30817bb8-8c7f-4e62-8ccc-703895f4861e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e77e9f8-e40b-40d9-9ac7-bf7eb5fb5653",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab442a62-cc9b-4d7d-9205-b80e8afe456d",
   "metadata": {},
   "source": [
    "## **매일경제(2018)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43516e7e-9dbf-455e-ac06-2e0f8a05f626",
   "metadata": {},
   "outputs": [],
   "source": [
    "arguments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30296aa2-cf44-43f2-9d2b-14c75f7c54d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "media_stock_prediction(craw_media, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ccba9e-7d89-4dfd-b320-d1e5875ab5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "corp_list = ['samsung', 'hyundai', 'lg', 'sk', 'celltrion']\n",
    "for i in range(len(corp_list)):\n",
    "    globals()[corp_list[i] + '_label'].to_csv('../../../../Final Data/2018_maeil_{0}.csv'.format(corp_list[i]), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5f8530-efc3-448e-a5c8-d3cfea8d8606",
   "metadata": {},
   "source": [
    "## **아시아경제(2018)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723577a3-4a1a-41ad-b962-29b84652d70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "arguments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be69a95-b549-4669-b99a-0099ce60e704",
   "metadata": {},
   "outputs": [],
   "source": [
    "media_stock_prediction(craw_media, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba908e6-acce-40be-8c35-dbd4d860d465",
   "metadata": {},
   "outputs": [],
   "source": [
    "corp_list = ['samsung', 'hyundai', 'lg', 'sk', 'celltrion']\n",
    "for i in range(len(corp_list)):\n",
    "    globals()[corp_list[i] + '_label'].to_csv('../../../../Final Data/2018_asia_{0}.csv'.format(corp_list[i]), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de5168a-5c0d-4d21-a7f4-ff4e8ba11e75",
   "metadata": {},
   "source": [
    "## **매일경제(2019)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb69ea59-97b8-49b0-8509-10bbc25fb380",
   "metadata": {},
   "outputs": [],
   "source": [
    "arguments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3220933-f18f-4446-ab0e-fe277e42014a",
   "metadata": {},
   "outputs": [],
   "source": [
    "media_stock_prediction(craw_media, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1a2e95-7628-4133-a33c-771dc7830d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "corp_list = ['samsung', 'hyundai', 'lg', 'sk', 'celltrion']\n",
    "for i in range(len(corp_list)):\n",
    "    globals()[corp_list[i] + '_label'].to_csv('../../../../Final Data/2019_maeil_{0}.csv'.format(corp_list[i]), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ebf73d-5346-40e5-8f29-824b392d7ba3",
   "metadata": {},
   "source": [
    "## **아시아경제(2019)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e5e421-b8de-46c7-a6f7-e94d4e6e9185",
   "metadata": {},
   "outputs": [],
   "source": [
    "arguments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0797194-d3bf-4c02-ac4c-190bc8eafe28",
   "metadata": {},
   "outputs": [],
   "source": [
    "media_stock_prediction(craw_media, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b2b50a-c817-4f8f-b124-ff334cceb85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "corp_list = ['samsung', 'hyundai', 'lg', 'sk', 'celltrion']\n",
    "for i in range(len(corp_list)):\n",
    "    globals()[corp_list[i] + '_label'].to_csv('../../../../Final Data/2019_asia_{0}.csv'.format(corp_list[i]), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e73bc70-3fbd-407b-89a9-5c44cddaec0d",
   "metadata": {},
   "source": [
    "## **매일경제(2020)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7df13bc-3ffb-4f2f-8f82-0659534e85ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "arguments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3e4426-bf2a-4ac9-b48a-bcde8dd7a539",
   "metadata": {},
   "outputs": [],
   "source": [
    "media_stock_prediction(craw_media, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2164f0-ee83-4ddb-8d01-91bc00bd128b",
   "metadata": {},
   "outputs": [],
   "source": [
    "corp_list = ['samsung', 'hyundai', 'lg', 'sk', 'celltrion']\n",
    "for i in range(len(corp_list)):\n",
    "    globals()[corp_list[i] + '_label'].to_csv('../../../../Final Data/2020_maeil_{0}.csv'.format(corp_list[i]), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528b4bd6-395b-4e7d-9f5d-35b640453193",
   "metadata": {},
   "source": [
    "## **아시아경제(2020)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e19118e-0c8a-45a3-ab8b-7aac386aad1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "arguments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352b2878-1c0a-4e00-aa1a-fb83fc68f6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "media_stock_prediction(craw_media, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73600224-a0a9-41da-a108-badf0fcea51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "corp_list = ['samsung', 'hyundai', 'lg', 'sk', 'celltrion']\n",
    "for i in range(len(corp_list)):\n",
    "    globals()[corp_list[i] + '_label'].to_csv('../../../../Final Data/2020_asia_{0}.csv'.format(corp_list[i]), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecdcb08-6d4e-4c36-b6d3-ca52f4a903a8",
   "metadata": {},
   "source": [
    "## **매일경제(2021)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4495415-0ff3-44bf-b720-b5d9d1375a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "arguments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487af0f5-c540-467a-907a-151a3806ae7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "media_stock_prediction(craw_media, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff104a3a-6226-474b-9f4c-393b30f772af",
   "metadata": {},
   "outputs": [],
   "source": [
    "corp_list = ['samsung', 'hyundai', 'lg', 'sk', 'celltrion']\n",
    "for i in range(len(corp_list)):\n",
    "    globals()[corp_list[i] + '_label'].to_csv('../../../../Final Data/2021_maeil_{0}.csv'.format(corp_list[i]), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3756f0d-3b2c-4357-9ab9-17f51faa307e",
   "metadata": {},
   "source": [
    "## **아시아경제(2021)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0422ce68-605b-4842-bc67-810cd1696137",
   "metadata": {},
   "outputs": [],
   "source": [
    "arguments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea577824-67ad-4603-addf-a61d91f3278b",
   "metadata": {},
   "outputs": [],
   "source": [
    "media_stock_prediction(craw_media, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371730f8-2d16-4761-b8e7-257b4eb7ee60",
   "metadata": {},
   "outputs": [],
   "source": [
    "corp_list = ['samsung', 'hyundai', 'lg', 'sk', 'celltrion']\n",
    "for i in range(len(corp_list)):\n",
    "    globals()[corp_list[i] + '_label'].to_csv('../../../../Final Data/2021_asia_{0}.csv'.format(corp_list[i]), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37958bc1-0433-45b0-ad30-eeb9c021e943",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python Multi",
   "language": "python",
   "name": "multi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
