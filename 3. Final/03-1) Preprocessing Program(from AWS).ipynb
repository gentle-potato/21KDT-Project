{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c09cc82-ef9a-441c-bebd-2c737253d68c",
   "metadata": {},
   "source": [
    "# **Preorocessing Program**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb6dfeae-4d19-4011-b0e4-0ae6d5a0593d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# DB 연결\n",
    "# !pip install pymysql\n",
    "import pymysql\n",
    "\n",
    "# DB에 저장\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# 실시간 주식가격 데이터\n",
    "# !pip install finance-datareader\n",
    "import FinanceDataReader as fdr\n",
    "\n",
    "# 텍스트 분석\n",
    "# 1) JAVA 설치, 2) Python 버전과 맞는 JPype1-py3 설치, 3) !pip install konlpy, 4) 설치 경로에서 jvm.py 파일 코드 67번 줄 주석 처리 \n",
    "from konlpy.tag import Okt\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# 모델 학습 및 평가\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# 모델 저장 및 로드\n",
    "import joblib\n",
    "\n",
    "# 기타\n",
    "import datetime\n",
    "from collections import Counter\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69c932f-e897-4456-b906-9a08ee1684c3",
   "metadata": {},
   "source": [
    "## **Develop Preprocessing Program**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "877a9e7e-ee7c-4ba0-8ded-7baca8832f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def arguments():\n",
    "    \n",
    "    \n",
    "    ### 1) 매체 선택\n",
    "    media_list = ['매일경제', '아시아경제', '삼프로TV', '슈카월드', '한국경제TV']\n",
    "    media_name = str(input('***매체명 입력(매일경제/아시아경제/삼프로TV/슈카월드/한국경제TV) :'))\n",
    "    while media_name not in media_list:\n",
    "        media_name = str(input('***매체명 다시 입력(매일경제/아시아경제/삼프로TV/슈카월드/한국경제TV) :'))\n",
    "        if media_name in media_list:\n",
    "            break\n",
    "    if media_name == '매일경제':\n",
    "        globals()['craw_media'] = 'maeil_news_craw'\n",
    "    elif media_name == '아시아경제':\n",
    "        globals()['craw_media'] = 'asia_news_craw'\n",
    "    elif media_name == '삼프로TV':\n",
    "        globals()['craw_media'] = 'youtube_sampro'\n",
    "    elif media_name == '슈카월드':\n",
    "        globals()['craw_media'] = 'youtube_suka'\n",
    "    else:\n",
    "        globals()['craw_media'] = 'youtube_hk'\n",
    "    \n",
    "    \n",
    "    ### 2) date 지정\n",
    "    \n",
    "    ## 2-1) 시작 날짜\n",
    "    globals()['start_date'] = str(input('***시작 날짜(YYYY-MM-DD) :'))\n",
    "    while len(globals()['start_date']) != 10:\n",
    "        start_date = str(input('***시작 날짜 다시 입력(YYYY-MM-DD) :'))\n",
    "        if len(globals()['start_date']) == 10:\n",
    "            break\n",
    "    globals()['start_date'] = globals()['start_date'].replace('/', '-')\n",
    "    globals()['start_date'] = globals()['start_date'].replace('.', '-')\n",
    "    \n",
    "    ## 2-2) 종료 날짜\n",
    "    globals()['end_date'] = str(input('***종료 날짜(YYYY-MM-DD) :'))\n",
    "    while len(globals()['end_date']) != 10:\n",
    "        globals()['end_date'] = str(input('***종료 날짜 다시 입력(YYYY-MM-DD) :'))\n",
    "        if len(end_date) == 10:\n",
    "            break\n",
    "    globals()['end_date'] = globals()['end_date'].replace('/', '-')\n",
    "    globals()['end_date'] = globals()['end_date'].replace('.', '-')\n",
    "    \n",
    "    ## 2-3) if 시작 날짜 < 종료 날짜: ...;;\n",
    "    if globals()['start_date'] > globals()['end_date']:\n",
    "        globals()['start_date'], globals()['end_date'] = globals()['end_date'], globals()['start_date']\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    return globals()['craw_media'], globals()['start_date'], globals()['end_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48310625-eb35-4abe-a930-8b9c14765984",
   "metadata": {},
   "outputs": [],
   "source": [
    "#*** 아직 YouTube 채널 크롤링 데이터는 별도의 전처리 코드 작성 필요 ***#\n",
    "def media_stock_prediction(craw_media, start_date, end_date):\n",
    "    #### 1. Read Data\n",
    "    \n",
    "    \n",
    "    ### 1) KOSELF 감성 어휘 사전\n",
    "    #*** 추후에 감성사전도 DB 연결해서 사용하도록 코드 변경 필요 ***#\n",
    "    with open('KOSELF_pos.txt', encoding='utf-8') as pos:\n",
    "        positive = pos.readlines()\n",
    "    positive = [pos.replace('\\n', '') for pos in positive]\n",
    "    with open('KOSELF_neg.txt', encoding='utf-8') as neg:\n",
    "        negative = neg.readlines()\n",
    "    negative = [neg.replace('\\n', '') for neg in negative]\n",
    "    \n",
    "    \n",
    "    ### 2) News Data from DB\n",
    "    db = pymysql.connect(user='root',\n",
    "                         passwd='1234',\n",
    "                         host='3.35.70.166',\n",
    "                         db='proj',\n",
    "                         charset='utf8')\n",
    "\n",
    "    cursor = db.cursor(pymysql.cursors.DictCursor)\n",
    "    \n",
    "    ## 2-1) 전체 종목 뉴스 데이터\n",
    "    corp_list = ['samsung', 'hyundai', 'lg', 'sk']\n",
    "    stock_num_list = ['005930', '005380', '051910', '000660']\n",
    "    \n",
    "    ## 2-2) DB의 date 컬럼과 형태 통일\n",
    "    start_date = start_date.replace('-', '')\n",
    "    end_date = end_date.replace('-', '')\n",
    "    for i in range(len(corp_list)):\n",
    "        sql = \"select * from {0}_{1} where (length(date)=10) and (date between {2}00 and {3}23)\".format(craw_media, stock_num_list[i], start_date, end_date)\n",
    "        cursor.execute(sql)\n",
    "        result = cursor.fetchall()\n",
    "\n",
    "        # DataFrame으로 변경\n",
    "        globals()[corp_list[i]] = pd.DataFrame(result)\n",
    "    \n",
    "    ## 2-3) text 컬럼의 NaN 제거\n",
    "    globals()[corp_list[i]].dropna(axis=0, inplace=True)\n",
    "        \n",
    "    ## 2-4) 날짜와 시간 구분\n",
    "    for i in range(len(corp_list)):\n",
    "        globals()[corp_list[i]].rename(columns={'date': 'datetime'}, inplace=True)\n",
    "\n",
    "        # DataFrame 형태를 통일하기 위해 date 컬럼 추가\n",
    "        globals()[corp_list[i]]['date'] = globals()[corp_list[i]]['datetime'].str[0:4] + '-' + globals()[corp_list[i]]['datetime'].str[4:6] + '-' + globals()[corp_list[i]]['datetime'].str[6:8]\n",
    "        globals()[corp_list[i]]['date'] = pd.to_datetime(globals()[corp_list[i]]['date'])\n",
    "\n",
    "        # 결측치 제거 → 데이터 로드 시 완료했기 때문에 그다지 필요하지 않은 과정\n",
    "        globals()[corp_list[i]] = globals()[corp_list[i]].dropna()\n",
    "\n",
    "        # 시간순으로 정렬\n",
    "        globals()[corp_list[i]].sort_values('datetime', inplace=True)\n",
    "        globals()[corp_list[i]].reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    \n",
    "    ### 3) FinanceDataReader\n",
    "    # 종료 날짜는 현재 시각을 기준으로\n",
    "    end_date = datetime.datetime.now().strftime(\"%Y%m%d\")\n",
    "    for i in range(len(corp_list)):\n",
    "        globals()['stock_' + corp_list[i]] = fdr.DataReader(stock_num_list[i], start=start_date, end=end_date).reset_index()\n",
    "    \n",
    "    \n",
    "    ### 4) Holidays\n",
    "    db = pymysql.connect(user='root',\n",
    "                         passwd='1234',\n",
    "                         host='3.35.70.166',\n",
    "                         db='proj',\n",
    "                         charset='utf8')\n",
    "\n",
    "    cursor = db.cursor(pymysql.cursors.DictCursor)\n",
    "\n",
    "    # 4-1) 주말 및 공휴일 데이터\n",
    "    sql = \"select * from holidays\"\n",
    "    cursor.execute(sql)\n",
    "    result = cursor.fetchall()\n",
    "    \n",
    "    # DataFrame으로 변경\n",
    "    globals()['holidays'] = pd.DataFrame(result)\n",
    "    \n",
    "    # 4-2) date 컬럼을 날짜 형식으로 변경\n",
    "    globals()['holidays']['date'] = pd.to_datetime(holidays['date'])\n",
    "    \n",
    "    \n",
    "    ### 5) Stop Words\n",
    "    #*** 추후에 Stop Words도 DB 연결해서 사용하도록 코드 변경 필요 ***#\n",
    "    with open('stopwords-ko.txt', encoding='utf-8') as sw:\n",
    "        globals()['stop_words'] = sw.readlines()\n",
    "    globals()['stop_words'] = [sw.replace('\\n', '') for sw in stop_words]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #### 2. Preprocessing\n",
    "    '''감성 어휘 사전 : negative / positive\n",
    "       뉴스 데이터 : samsung / hyundai / lg / sk\n",
    "       주식 데이터 : stock_samsung / stock_hyundai / stock_lg / stock_sk\n",
    "       공휴일 데이터 : holidays'''\n",
    "    \n",
    "    \n",
    "    ### 1) 뉴스 데이터 날짜 조정\n",
    "    \n",
    "    ## 1-1)업로드 시각 컬럼 추가\n",
    "    for i in range(len(corp_list)):\n",
    "        globals()[corp_list[i]]['time'] = globals()[corp_list[i]]['datetime'].str[-2:]\n",
    "    \n",
    "    ## 1-2) 전일 15시 ~ 금일 15시로 날짜 조정\n",
    "    after_market = ['15', '16', '17', '18', '19', '20', '21', '22', '23']\n",
    "\n",
    "    for i in range(len(corp_list)):\n",
    "        for j in range(len(globals()[corp_list[i]]['time'])):\n",
    "            if globals()[corp_list[i]]['time'][j] in after_market:\n",
    "                globals()[corp_list[i]]['date'][j] += datetime.timedelta(1)\n",
    "            else:\n",
    "                pass\n",
    "    \n",
    "    ## 1-3) 텍스트 전처리\n",
    "    for i in range(len(corp_list)):\n",
    "        globals()[corp_list[i]]['text'] = globals()[corp_list[i]]['text'].str.replace('[\\n|\\t|\\r]', '')\n",
    "    \n",
    "    \n",
    "    ### 2) 주말 및 공휴일 제외\n",
    "    \n",
    "    ## 2-1) 주말 및 공휴일만 추출\n",
    "    market_closed = globals()['holidays'][globals()['holidays']['holiday']==\"O\"].reset_index(drop=True)\n",
    "    \n",
    "    ## 2-3) 휴장일 List 생성\n",
    "    market_closed_list = list(market_closed['date'])\n",
    "    \n",
    "    ## 2-4) iteration limit 조정\n",
    "    limit_number = 15000\n",
    "    sys.setrecursionlimit(limit_number)\n",
    "    \n",
    "    ## 2-5) 휴장일 제외 함수 적용\n",
    "    # 주말 및 공휴일 제외 함수\n",
    "    def stock_market_closed(df):\n",
    "        for i in range(len(df['date'])):\n",
    "            if df['date'][i] in market_closed_list:\n",
    "                df['date'][i] += datetime.timedelta(1)\n",
    "                stock_market_closed(df)\n",
    "            else:\n",
    "                pass\n",
    "        return df\n",
    "    \n",
    "    for i in range(len(corp_list)):\n",
    "        stock_market_closed(globals()[corp_list[i]])\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #### 3. Sentiment Analysis\n",
    "    \n",
    "    \n",
    "    ### 1) 종목별 긍부정 Score 계산\n",
    "    for i in range(len(corp_list)):\n",
    "        globals()[corp_list[i]]['score'] = 0\n",
    "        tokenizer = Okt()\n",
    "\n",
    "        for x in range(len(globals()[corp_list[i]]['date'])):\n",
    "            score = 0\n",
    "            num = tokenizer.nouns(globals()[corp_list[i]]['text'][x])\n",
    "            for y in num:\n",
    "                # KOSELF 감성 어휘 사전\n",
    "                if y in positive:\n",
    "                    score += 1\n",
    "                elif y in negative:\n",
    "                    score -= 1\n",
    "                else:\n",
    "                    score = score\n",
    "\n",
    "            globals()[corp_list[i]]['score'][x] = score\n",
    "    \n",
    "    \n",
    "    ### 2) 주식가격 데이터와 결합\n",
    "    corp_label_list = []\n",
    "    for i in range(len(corp_list)):\n",
    "        \n",
    "        ### 2-1) 결합\n",
    "        globals()[corp_list[i] + '_label'] = pd.merge(globals()[corp_list[i]], globals()['stock_' + corp_list[i]], how='left', left_on='date', right_on='Date')\n",
    "        globals()[corp_list[i] + '_label'].drop('Date', axis=1, inplace=True)\n",
    "        \n",
    "        ### 2-2) UpDown과 Extremely_Changed(Change 상하위 5%) 컬럼 생성\n",
    "        # 주식 매매 수수료 평균 : 0.1% 정도(?) → 0을 추가해도 1, -1만 나옴\n",
    "        globals()[corp_list[i] + '_label']['UpDown'] = np.where((globals()[corp_list[i] + '_label']['Close'] * globals()[corp_list[i] + '_label']['Change'])>(globals()[corp_list[i] + '_label']['Close']*0.001), 1,\n",
    "                                                                np.where((globals()[corp_list[i] + '_label']['Close']*globals()[corp_list[i] + '_label']['Change']<(globals()[corp_list[i] + '_label']['Close']*0.001), -1, 0)))\n",
    "#         # 단순히 Change가 (+), 0, (-)인지에 따라 각각 1, 0, -1\n",
    "#         globals()[corp_list[i] + '_label']['UpDown'] = np.where(globals()[corp_list[i] + '_label']['Change']>0, 1,\n",
    "#                                                                 np.where(globals()[corp_list[i] + '_label']['Change']<0, -1, 0))\n",
    "        globals()[corp_list[i] + '_label']['Extremely_Changed'] = np.where((globals()[corp_list[i] + '_label']['Change']>globals()[corp_list[i] + '_label']['Change'].quantile(.95)) & (globals()[corp_list[i] + '_label']['Change']>0), 1,\n",
    "                                                                            np.where((globals()[corp_list[i] + '_label']['Change']<globals()[corp_list[i] + '_label']['Change'].quantile(.05)) & (globals()[corp_list[i] + '_label']['Change']<0), -1, 0))\n",
    "        \n",
    "        ### 2-3) List에 추가\n",
    "        corp_label_list.append(globals()[corp_list[i] + '_label'])\n",
    "    \n",
    "    \n",
    "    ### 3) 전체 종목 DataFrame 통합\n",
    "    globals()['total_label'] = pd.concat(corp_label_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae53a3cd-f82d-4d4f-a49d-1cb7d516052f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "***매체명 입력(매일경제/아시아경제/삼프로TV/슈카월드/한국경제TV) : 매일경제\n",
      "***시작 날짜(YYYY-MM-DD) : 2019-01-01\n",
      "***종료 날짜(YYYY-MM-DD) : 2019-04-30\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('maeil_news_craw', '2019-01-01', '2019-04-30')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arguments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "282bddee-e0f7-4d8e-8ce8-7444f168a71c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('maeil_news_craw', '2019-01-01', '2019-04-30')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "craw_media, start_date, end_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a24b0152-73ff-4cec-a7c2-66bdd8c482a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "media_stock_prediction(craw_media, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "593a4520-fc6c-4b95-8802-c270d06e38d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>dd</th>\n",
       "      <th>explanation</th>\n",
       "      <th>weekend</th>\n",
       "      <th>holiday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mon</td>\n",
       "      <td>새해</td>\n",
       "      <td>None</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Tue</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Wed</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Thu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Fri</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1821</th>\n",
       "      <td>2022-12-27</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>Tue</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1822</th>\n",
       "      <td>2022-12-28</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>Wed</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1823</th>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>Thu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1824</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>Fri</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825</th>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>Sat</td>\n",
       "      <td>None</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1826 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  year  month  day   dd explanation weekend holiday\n",
       "0    2018-01-01  2018      1    1  Mon          새해    None       O\n",
       "1    2018-01-02  2018      1    2  Tue        None    None    None\n",
       "2    2018-01-03  2018      1    3  Wed        None    None    None\n",
       "3    2018-01-04  2018      1    4  Thu        None    None    None\n",
       "4    2018-01-05  2018      1    5  Fri        None    None    None\n",
       "...         ...   ...    ...  ...  ...         ...     ...     ...\n",
       "1821 2022-12-27  2022     12   27  Tue        None    None    None\n",
       "1822 2022-12-28  2022     12   28  Wed        None    None    None\n",
       "1823 2022-12-29  2022     12   29  Thu        None    None    None\n",
       "1824 2022-12-30  2022     12   30  Fri        None    None    None\n",
       "1825 2022-12-31  2022     12   31  Sat        None       O       O\n",
       "\n",
       "[1826 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5033cae6-f436-4dac-a86e-aeabc01a020b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline을 통한 Logistic Regression의 예측 정확도 : 0.480\n"
     ]
    }
   ],
   "source": [
    "# 모델 로드\n",
    "grid_cv_pipe = joblib.load('../../../../Code/TF-IDF.h5') \n",
    "pred = grid_cv_pipe.predict(total_label['text'])\n",
    "\n",
    "# Acuuracy 확인\n",
    "print('Pipeline을 통한 Logistic Regression의 예측 정확도 : {0:.3f}'.format(accuracy_score(total_label['UpDown'], pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97ac78fa-59ea-4389-9a90-70398e2b1d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline을 통한 Logistic Regression의 예측 정확도 : 0.480\n"
     ]
    }
   ],
   "source": [
    "# 모델 로드\n",
    "grid_cv_pipe = joblib.load('../../../../Code/Model/TF-IDF.pkl') \n",
    "pred = grid_cv_pipe.predict(total_label['text'])\n",
    "\n",
    "# Acuuracy 확인\n",
    "print('Pipeline을 통한 Logistic Regression의 예측 정확도 : {0:.3f}'.format(accuracy_score(total_label['UpDown'], pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50dc8ebb-99eb-4dac-99a4-1756a7df5ace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -1, -1, ..., -1, -1,  1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f738dfc8-6b53-4d9d-a54b-3cd1b99e8b77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({-1: 1515, 1: 1655})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73abe086-1ce6-4496-a028-cbf485307a71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python Multi",
   "language": "python",
   "name": "multi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
