{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9381e171-62d5-476d-941a-c403b6647050",
   "metadata": {},
   "source": [
    "# **2019년**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "484d9ab4-4f93-4f71-a658-0113ac1e967a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# DB 연결\n",
    "# !pip install pymysql\n",
    "import pymysql\n",
    "\n",
    "# DB에 저장\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# 실시간 주식가격 데이터\n",
    "# !pip install finance-datareader\n",
    "import FinanceDataReader as fdr\n",
    "\n",
    "# 텍스트 분석\n",
    "# 1) JAVA 설치, 2) Python 버전과 맞는 JPype1-py3 설치, 3) !pip install konlpy, 4) 설치 경로에서 jvm.py 파일 코드 67번 줄 주석 처리 \n",
    "from konlpy.tag import Okt\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# 모델 학습 및 평가\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# 모델 저장 및 로드\n",
    "import joblib\n",
    "\n",
    "# 기타\n",
    "import datetime\n",
    "from collections import Counter\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3fab942-fc0c-4676-84a2-eb1f934139e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def arguments():\n",
    "    \n",
    "    \n",
    "    ### 1) 매체 선택\n",
    "    media_list = ['매일경제', '아시아경제', '삼프로TV', '슈카월드', '한국경제TV']\n",
    "    media_name = str(input('***매체명 입력(매일경제/아시아경제/삼프로TV/슈카월드/한국경제TV) :'))\n",
    "    while media_name not in media_list:\n",
    "        media_name = str(input('***매체명 다시 입력(매일경제/아시아경제/삼프로TV/슈카월드/한국경제TV) :'))\n",
    "        if media_name in media_list:\n",
    "            break\n",
    "    if media_name == '매일경제':\n",
    "        globals()['craw_media'] = 'maeil_news_craw'\n",
    "    elif media_name == '아시아경제':\n",
    "        globals()['craw_media'] = 'asia_news_craw'\n",
    "    elif media_name == '삼프로TV':\n",
    "        globals()['craw_media'] = 'youtube_sampro'\n",
    "    elif media_name == '슈카월드':\n",
    "        globals()['craw_media'] = 'youtube_suka'\n",
    "    else:\n",
    "        globals()['craw_media'] = 'youtube_hk'\n",
    "    \n",
    "    \n",
    "    ### 2) date 지정\n",
    "    \n",
    "    ## 2-1) 시작 날짜\n",
    "    globals()['start_date'] = str(input('***시작 날짜(YYYY-MM-DD) :'))\n",
    "    while len(globals()['start_date']) != 10:\n",
    "        start_date = str(input('***시작 날짜 다시 입력(YYYY-MM-DD) :'))\n",
    "        if len(globals()['start_date']) == 10:\n",
    "            break\n",
    "    globals()['start_date'] = globals()['start_date'].replace('/', '-')\n",
    "    globals()['start_date'] = globals()['start_date'].replace('.', '-')\n",
    "    \n",
    "    ## 2-2) 종료 날짜\n",
    "    globals()['end_date'] = str(input('***종료 날짜(YYYY-MM-DD) :'))\n",
    "    while len(globals()['end_date']) != 10:\n",
    "        globals()['end_date'] = str(input('***종료 날짜 다시 입력(YYYY-MM-DD) :'))\n",
    "        if len(end_date) == 10:\n",
    "            break\n",
    "    globals()['end_date'] = globals()['end_date'].replace('/', '-')\n",
    "    globals()['end_date'] = globals()['end_date'].replace('.', '-')\n",
    "    \n",
    "    ## 2-3) if 시작 날짜 < 종료 날짜: ...;;\n",
    "    if globals()['start_date'] > globals()['end_date']:\n",
    "        globals()['start_date'], globals()['end_date'] = globals()['end_date'], globals()['start_date']\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    return globals()['craw_media'], globals()['start_date'], globals()['end_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a2f0bb9-08fa-4ffb-8842-54867929e7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#*** 아직 YouTube 채널 크롤링 데이터는 별도의 전처리 코드 작성 필요 ***#\n",
    "def media_stock_prediction(craw_media, start_date, end_date):\n",
    "    #### 1. Read Data\n",
    "    \n",
    "    \n",
    "    ### 1) KOSELF 감성 어휘 사전\n",
    "    #*** 추후에 감성사전도 DB 연결해서 사용하도록 코드 변경 필요 ***#\n",
    "    with open('KOSELF_pos.txt', encoding='utf-8') as pos:\n",
    "        positive = pos.readlines()\n",
    "    positive = [pos.replace('\\n', '') for pos in positive]\n",
    "    with open('KOSELF_neg.txt', encoding='utf-8') as neg:\n",
    "        negative = neg.readlines()\n",
    "    negative = [neg.replace('\\n', '') for neg in negative]\n",
    "    \n",
    "    \n",
    "    ### 2) News Data from DB\n",
    "    db = pymysql.connect(user='root',\n",
    "                         passwd='0808',\n",
    "                         host='127.0.0.1',\n",
    "                         db='proj',\n",
    "                         charset='utf8')\n",
    "\n",
    "    cursor = db.cursor(pymysql.cursors.DictCursor)\n",
    "    \n",
    "    ## 2-1) 전체 종목 뉴스 데이터\n",
    "    corp_list = ['samsung', 'hyundai', 'lg', 'sk']\n",
    "    stock_num_list = ['005930', '005380', '051910', '000660']\n",
    "    \n",
    "    ## 2-2) DB의 date 컬럼과 형태 통일\n",
    "    start_date = start_date.replace('-', '')\n",
    "    end_date = end_date.replace('-', '')\n",
    "    for i in range(len(corp_list)):\n",
    "        sql = \"select * from {0}_{1} where (length(date)=10) and (date between {2}00 and {3}23)\".format(craw_media, stock_num_list[i], start_date, end_date)\n",
    "        cursor.execute(sql)\n",
    "        result = cursor.fetchall()\n",
    "\n",
    "        # DataFrame으로 변경\n",
    "        globals()[corp_list[i]] = pd.DataFrame(result)\n",
    "    \n",
    "    ## 2-3) text 컬럼의 NaN 제거\n",
    "    globals()[corp_list[i]].dropna(axis=0, inplace=True)\n",
    "        \n",
    "    ## 2-4) 날짜와 시간 구분\n",
    "    for i in range(len(corp_list)):\n",
    "        globals()[corp_list[i]].rename(columns={'date': 'datetime'}, inplace=True)\n",
    "\n",
    "        # DataFrame 형태를 통일하기 위해 date 컬럼 추가\n",
    "        globals()[corp_list[i]]['date'] = globals()[corp_list[i]]['datetime'].str[0:4] + '-' + globals()[corp_list[i]]['datetime'].str[4:6] + '-' + globals()[corp_list[i]]['datetime'].str[6:8]\n",
    "        globals()[corp_list[i]]['date'] = pd.to_datetime(globals()[corp_list[i]]['date'])\n",
    "\n",
    "        # 결측치 제거 → 데이터 로드 시 완료했기 때문에 그다지 필요하지 않은 과정\n",
    "        globals()[corp_list[i]] = globals()[corp_list[i]].dropna()\n",
    "\n",
    "        # 시간순으로 정렬\n",
    "        globals()[corp_list[i]].sort_values('datetime', inplace=True)\n",
    "        globals()[corp_list[i]].reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    \n",
    "    ### 3) FinanceDataReader\n",
    "    # 종료 날짜는 현재 시각을 기준으로\n",
    "    end_date = datetime.datetime.now().strftime(\"%Y%m%d\")\n",
    "    for i in range(len(corp_list)):\n",
    "        globals()['stock_' + corp_list[i]] = fdr.DataReader(stock_num_list[i], start=start_date, end=end_date).reset_index()\n",
    "    \n",
    "    \n",
    "    ### 4) Holidays\n",
    "    db = pymysql.connect(user='root',\n",
    "                         passwd='0808',\n",
    "                         host='127.0.0.1',\n",
    "                         db='proj',\n",
    "                         charset='utf8')\n",
    "\n",
    "    cursor = db.cursor(pymysql.cursors.DictCursor)\n",
    "\n",
    "    # 4-1) 주말 및 공휴일 데이터\n",
    "    sql = \"select * from holidays\"\n",
    "    cursor.execute(sql)\n",
    "    result = cursor.fetchall()\n",
    "    \n",
    "    # DataFrame으로 변경\n",
    "    globals()['holidays'] = pd.DataFrame(result)\n",
    "    \n",
    "    # 4-2) date 컬럼을 날짜 형식으로 변경\n",
    "    globals()['holidays']['date'] = pd.to_datetime(holidays['date'])\n",
    "    \n",
    "    \n",
    "    ### 5) Stop Words\n",
    "    #*** 추후에 Stop Words도 DB 연결해서 사용하도록 코드 변경 필요 ***#\n",
    "    with open('stopwords-ko.txt', encoding='utf-8') as sw:\n",
    "        globals()['stop_words'] = sw.readlines()\n",
    "    globals()['stop_words'] = [sw.replace('\\n', '') for sw in stop_words]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #### 2. Preprocessing\n",
    "    '''감성 어휘 사전 : negative / positive\n",
    "       뉴스 데이터 : samsung / hyundai / lg / sk\n",
    "       주식 데이터 : stock_samsung / stock_hyundai / stock_lg / stock_sk\n",
    "       공휴일 데이터 : holidays'''\n",
    "    \n",
    "    \n",
    "    ### 1) 뉴스 데이터 날짜 조정\n",
    "    \n",
    "    ## 1-1)업로드 시각 컬럼 추가\n",
    "    for i in range(len(corp_list)):\n",
    "        globals()[corp_list[i]]['time'] = globals()[corp_list[i]]['datetime'].str[-2:]\n",
    "    \n",
    "    ## 1-2) 전일 15시 ~ 금일 15시로 날짜 조정\n",
    "    after_market = ['15', '16', '17', '18', '19', '20', '21', '22', '23']\n",
    "\n",
    "    for i in range(len(corp_list)):\n",
    "        for j in range(len(globals()[corp_list[i]]['time'])):\n",
    "            if globals()[corp_list[i]]['time'][j] in after_market:\n",
    "                globals()[corp_list[i]]['date'][j] += datetime.timedelta(1)\n",
    "            else:\n",
    "                pass\n",
    "    \n",
    "    ## 1-3) 텍스트 전처리\n",
    "    for i in range(len(corp_list)):\n",
    "        globals()[corp_list[i]]['text'] = globals()[corp_list[i]]['text'].str.replace('[\\n|\\t|\\r]', '')\n",
    "    \n",
    "    \n",
    "    ### 2) 주말 및 공휴일 제외\n",
    "    \n",
    "    ## 2-1) 주말 및 공휴일만 추출\n",
    "    market_closed = globals()['holidays'][globals()['holidays']['holiday']==\"O\"].reset_index(drop=True)\n",
    "    \n",
    "    ## 2-3) 휴장일 List 생성\n",
    "    market_closed_list = list(market_closed['date'])\n",
    "    \n",
    "    ## 2-4) iteration limit 조정\n",
    "    limit_number = 15000\n",
    "    sys.setrecursionlimit(limit_number)\n",
    "    \n",
    "    ## 2-5) 휴장일 제외 함수 적용\n",
    "    # 주말 및 공휴일 제외 함수\n",
    "    def stock_market_closed(df):\n",
    "        for i in range(len(df['date'])):\n",
    "            if df['date'][i] in market_closed_list:\n",
    "                df['date'][i] += datetime.timedelta(1)\n",
    "                stock_market_closed(df)\n",
    "            else:\n",
    "                pass\n",
    "        return df\n",
    "    \n",
    "    for i in range(len(corp_list)):\n",
    "        stock_market_closed(globals()[corp_list[i]])\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #### 3. Sentiment Analysis\n",
    "    \n",
    "    \n",
    "    ### 1) 종목별 긍부정 Score 계산\n",
    "    for i in range(len(corp_list)):\n",
    "        globals()[corp_list[i]]['score'] = 0\n",
    "        tokenizer = Okt()\n",
    "\n",
    "        for x in range(len(globals()[corp_list[i]]['date'])):\n",
    "            score = 0\n",
    "            num = tokenizer.nouns(globals()[corp_list[i]]['text'][x])\n",
    "            for y in num:\n",
    "                # KOSELF 감성 어휘 사전\n",
    "                if y in positive:\n",
    "                    score += 1\n",
    "                elif y in negative:\n",
    "                    score -= 1\n",
    "                else:\n",
    "                    score = score\n",
    "\n",
    "            globals()[corp_list[i]]['score'][x] = score\n",
    "    \n",
    "    \n",
    "    ### 2) 주식가격 데이터와 결합\n",
    "    corp_label_list = []\n",
    "    for i in range(len(corp_list)):\n",
    "        \n",
    "        ### 2-1) 결합\n",
    "        globals()[corp_list[i] + '_label'] = pd.merge(globals()[corp_list[i]], globals()['stock_' + corp_list[i]], how='left', left_on='date', right_on='Date')\n",
    "        globals()[corp_list[i] + '_label'].drop('Date', axis=1, inplace=True)\n",
    "        \n",
    "        ### 2-2) UpDown과 Extremely_Changed(Change 상하위 5%) 컬럼 생성\n",
    "        # 주식 매매 수수료 평균 : 0.1% 정도(?) → 0을 추가해도 1, -1만 나옴\n",
    "        globals()[corp_list[i] + '_label']['UpDown'] = np.where((globals()[corp_list[i] + '_label']['Close']*globals()[corp_list[i] + '_label']['Change'])>(globals()[corp_list[i] + '_label']['Close']*0.001), 1,\n",
    "                                                                np.where((globals()[corp_list[i] + '_label']['Close']*globals()[corp_list[i] + '_label']['Change']<globals()[corp_list[i] + '_label']['Close']*0.001), -1, 0))\n",
    "#         # 단순히 Change가 (+), 0, (-)인지에 따라 각각 1, 0, -1\n",
    "#         globals()[corp_list[i] + '_label']['UpDown'] = np.where(globals()[corp_list[i] + '_label']['Change']>0, 1,\n",
    "#                                                                 np.where(globals()[corp_list[i] + '_label']['Change']<0, -1, 0))\n",
    "        globals()[corp_list[i] + '_label']['Extremely_Changed'] = np.where((globals()[corp_list[i] + '_label']['Change']>globals()[corp_list[i] + '_label']['Change'].quantile(.95)) & (globals()[corp_list[i] + '_label']['Change']>0), 1,\n",
    "                                                                            np.where((globals()[corp_list[i] + '_label']['Change']<globals()[corp_list[i] + '_label']['Change'].quantile(.05)) & (globals()[corp_list[i] + '_label']['Change']<0), -1, 0))\n",
    "        \n",
    "        ### 2-3) List에 추가\n",
    "        corp_label_list.append(globals()[corp_list[i] + '_label'])\n",
    "    \n",
    "    \n",
    "    ### 3) 전체 종목 DataFrame 통합\n",
    "    globals()['total_label'] = pd.concat(corp_label_list, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337b9a3b-26e3-4b37-9e40-4dac84f88f3a",
   "metadata": {},
   "source": [
    "## **매일경제**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f785f9d-c17b-4de0-a358-61bacbe5a6d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "***매체명 입력(매일경제/아시아경제/삼프로TV/슈카월드/한국경제TV) : 매일경제\n",
      "***시작 날짜(YYYY-MM-DD) : 2019-01-01\n",
      "***종료 날짜(YYYY-MM-DD) : 2019-12-31\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('maeil_news_craw', '2019-01-01', '2019-12-31')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arguments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13ff2448-3698-4a5c-9b4b-dbce15a29177",
   "metadata": {},
   "outputs": [],
   "source": [
    "media_stock_prediction(craw_media, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3143d421-4a12-41be-a6bb-357a401ac387",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_label.to_csv('../../../../Code/Data/2019_maeil.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5af4f60-36a7-45b9-bf00-9d6783fda587",
   "metadata": {},
   "source": [
    "## **아시아경제**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8852dfb-c447-4d6b-ad45-3cb9b7922614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "***매체명 입력(매일경제/아시아경제/삼프로TV/슈카월드/한국경제TV) : 아시아경제\n",
      "***시작 날짜(YYYY-MM-DD) : 2019-01-01\n",
      "***종료 날짜(YYYY-MM-DD) : 2019-12-31\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('asia_news_craw', '2019-01-01', '2019-12-31')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arguments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06b636e0-ee77-46d9-afed-fdb12e35b670",
   "metadata": {},
   "outputs": [],
   "source": [
    "media_stock_prediction(craw_media, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02ffe582-78a0-4db0-a400-4cf9054aba6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_label.to_csv('../../../../Code/Data/2019_asia.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e12d862-71c1-499b-b4c4-04328f76ee5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python Multi",
   "language": "python",
   "name": "multi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
