{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9381e171-62d5-476d-941a-c403b6647050",
   "metadata": {},
   "source": [
    "# **2021년**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "484d9ab4-4f93-4f71-a658-0113ac1e967a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "### Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "### DB 연결\n",
    "# !pip install pymysql\n",
    "import pymysql\n",
    "\n",
    "### DB에 저장\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "### 실시간 주식가격 데이터\n",
    "# !pip install finance-datareader\n",
    "import FinanceDataReader as fdr\n",
    "\n",
    "### 텍스트 분석\n",
    "## KoNLPy\n",
    "# 1) JAVA 설치, 2) Python 버전과 맞는 JPype1-py3 설치, 3) !pip install konlpy, 4) 설치 경로에서 jvm.py 파일 코드 67번 줄 주석 처리 \n",
    "from konlpy.tag import Okt\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import re\n",
    "## FastText\n",
    "# !pip install gensim\n",
    "# !pip install fasttext\n",
    "import fasttext\n",
    "import fasttext.util\n",
    "# Facebook 한국어 Embedding 모델 다운로드 → 한 번만 설치하면 됨\n",
    "fasttext.util.download_model('ko', if_exists='ignore')\n",
    "# 유사도 계산\n",
    "from gensim import models\n",
    "\n",
    "### 모델 학습 및 평가\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "### 모델 저장 및 로드\n",
    "import joblib\n",
    "\n",
    "### 기타\n",
    "import datetime\n",
    "from collections import Counter\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3fab942-fc0c-4676-84a2-eb1f934139e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def arguments():\n",
    "    \n",
    "    \n",
    "    ### 1) 매체 선택\n",
    "    media_list = ['매일경제', '아시아경제', '삼프로TV', '슈카월드', '한국경제TV']\n",
    "    media_name = str(input('***매체명 입력(매일경제/아시아경제/삼프로TV/슈카월드/한국경제TV) :'))\n",
    "    while media_name not in media_list:\n",
    "        media_name = str(input('***매체명 다시 입력(매일경제/아시아경제/삼프로TV/슈카월드/한국경제TV) :'))\n",
    "        if media_name in media_list:\n",
    "            break\n",
    "    if media_name == '매일경제':\n",
    "        globals()['craw_media'] = 'maeil_news_craw'\n",
    "    elif media_name == '아시아경제':\n",
    "        globals()['craw_media'] = 'asia_news_craw'\n",
    "    elif media_name == '삼프로TV':\n",
    "        globals()['craw_media'] = 'youtube_sampro'\n",
    "    elif media_name == '슈카월드':\n",
    "        globals()['craw_media'] = 'youtube_suka'\n",
    "    else:\n",
    "        globals()['craw_media'] = 'youtube_hk'\n",
    "    \n",
    "    \n",
    "    ### 2) date 지정\n",
    "    \n",
    "    ## 2-1) 시작 날짜\n",
    "    globals()['start_date'] = str(input('***시작 날짜(YYYY-MM-DD) :'))\n",
    "    while len(globals()['start_date']) != 10:\n",
    "        start_date = str(input('***시작 날짜 다시 입력(YYYY-MM-DD) :'))\n",
    "        if len(globals()['start_date']) == 10:\n",
    "            break\n",
    "    globals()['start_date'] = globals()['start_date'].replace('/', '-')\n",
    "    globals()['start_date'] = globals()['start_date'].replace('.', '-')\n",
    "    \n",
    "    ## 2-2) 종료 날짜\n",
    "    globals()['end_date'] = str(input('***종료 날짜(YYYY-MM-DD) :'))\n",
    "    while len(globals()['end_date']) != 10:\n",
    "        globals()['end_date'] = str(input('***종료 날짜 다시 입력(YYYY-MM-DD) :'))\n",
    "        if len(end_date) == 10:\n",
    "            break\n",
    "    globals()['end_date'] = globals()['end_date'].replace('/', '-')\n",
    "    globals()['end_date'] = globals()['end_date'].replace('.', '-')\n",
    "    \n",
    "    ## 2-3) if 시작 날짜 < 종료 날짜: ...;;\n",
    "    if globals()['start_date'] > globals()['end_date']:\n",
    "        globals()['start_date'], globals()['end_date'] = globals()['end_date'], globals()['start_date']\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    return globals()['craw_media'], globals()['start_date'], globals()['end_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6efeb770-56c6-4c64-8ba4-861ae36854de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#*** 아직 YouTube 채널 크롤링 데이터는 별도의 전처리 코드 작성 필요 ***#\n",
    "def media_stock_prediction(craw_media, start_date, end_date):\n",
    "    #### 1. Read Data\n",
    "    \n",
    "    \n",
    "    ### 1) KOSELF 감성 어휘 사전\n",
    "    #*** 추후에 감성사전도 DB 연결해서 사용하도록 코드 변경 필요 ***#\n",
    "    with open('KOSELF_pos.txt', encoding='utf-8') as pos:\n",
    "        positive = pos.readlines()\n",
    "    positive = [pos.replace('\\n', '') for pos in positive]\n",
    "    with open('KOSELF_neg.txt', encoding='utf-8') as neg:\n",
    "        negative = neg.readlines()\n",
    "    negative = [neg.replace('\\n', '') for neg in negative]\n",
    "    \n",
    "    \n",
    "    ### 2) News Data from DB\n",
    "    db = pymysql.connect(user='root',\n",
    "                         passwd='0808',\n",
    "                         host='127.0.0.1',\n",
    "                         db='proj',\n",
    "                         charset='utf8')\n",
    "\n",
    "    cursor = db.cursor(pymysql.cursors.DictCursor)\n",
    "    \n",
    "    ## 2-1) 전체 종목 뉴스 데이터\n",
    "    corp_list = ['samsung', 'hyundai', 'lg', 'sk', 'celltrion']\n",
    "    stock_num_list = ['005930', '005380', '051910', '000660', '068270']\n",
    "    \n",
    "    ## 2-2) DB의 date 컬럼과 형태 통일\n",
    "    start_date = start_date.replace('-', '')\n",
    "    end_date = end_date.replace('-', '')\n",
    "    for i in range(len(corp_list)):\n",
    "        sql = \"select * from {0}_{1} where (length(date)=10) and (date between {2}00 and {3}23)\".format(craw_media, stock_num_list[i], start_date, end_date)\n",
    "        cursor.execute(sql)\n",
    "        result = cursor.fetchall()\n",
    "\n",
    "        # DataFrame으로 변경\n",
    "        globals()[corp_list[i]] = pd.DataFrame(result)\n",
    "    \n",
    "    db.close()   # 메모리 절약\n",
    "    \n",
    "    ## 2-3) 날짜와 시간 구분\n",
    "    for i in range(len(corp_list)):\n",
    "        globals()[corp_list[i]].rename(columns={'date': 'datetime'}, inplace=True)\n",
    "\n",
    "        # DataFrame 형태를 통일하기 위해 date 컬럼 추가\n",
    "        globals()[corp_list[i]]['date'] = globals()[corp_list[i]]['datetime'].str[0:4] + '-' + globals()[corp_list[i]]['datetime'].str[4:6] + '-' + globals()[corp_list[i]]['datetime'].str[6:8]\n",
    "        globals()[corp_list[i]]['date'] = pd.to_datetime(globals()[corp_list[i]]['date'])\n",
    "\n",
    "        # 결측치 제거 → 데이터 로드 시 완료했기 때문에 그다지 필요하지 않은 과정\n",
    "        globals()[corp_list[i]] = globals()[corp_list[i]].dropna()\n",
    "\n",
    "        # 시간순으로 정렬\n",
    "        globals()[corp_list[i]].sort_values('datetime', inplace=True)\n",
    "        globals()[corp_list[i]].reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    \n",
    "    ### 3) FinanceDataReader\n",
    "    # 종료 날짜는 현재 시각을 기준으로\n",
    "    end_date = datetime.datetime.now().strftime(\"%Y%m%d\")\n",
    "    for i in range(len(corp_list)):\n",
    "        globals()['stock_' + corp_list[i]] = fdr.DataReader(stock_num_list[i], start=start_date, end=end_date).reset_index()\n",
    "    \n",
    "    \n",
    "    ### 4) Holidays\n",
    "    db = pymysql.connect(user='root',\n",
    "                         passwd='0808',\n",
    "                         host='127.0.0.1',\n",
    "                         db='proj',\n",
    "                         charset='utf8')\n",
    "\n",
    "    cursor = db.cursor(pymysql.cursors.DictCursor)\n",
    "\n",
    "    # 4-1) 주말 및 공휴일 데이터\n",
    "    sql = \"select * from holidays\"\n",
    "    cursor.execute(sql)\n",
    "    result = cursor.fetchall()\n",
    "    \n",
    "    # DataFrame으로 변경\n",
    "    globals()['holidays'] = pd.DataFrame(result)\n",
    "    \n",
    "    db.close()   # 메모리 절약\n",
    "    \n",
    "    # 4-2) date 컬럼을 날짜 형식으로 변경\n",
    "    globals()['holidays']['date'] = pd.to_datetime(holidays['date'])\n",
    "    \n",
    "    \n",
    "    ### 5) Stop Words\n",
    "#     #*** 추후에 Stop Words도 DB 연결해서 사용하도록 코드 변경 필요 ***#\n",
    "#     with open('stopwords-ko.txt', encoding='utf-8') as sw:\n",
    "#         globals()['stop_words'] = sw.readlines()\n",
    "#     globals()['stop_words'] = [sw.replace('\\n', '') for sw in stop_words]\n",
    "    # GitHub로부터 Stop Words 로드\n",
    "    stopwords = pd.read_csv(\"https://raw.githubusercontent.com/yoonkt200/FastCampusDataset/master/korean_stopwords.txt\")\n",
    "    # Stop Words List에 각 매체명 추가\n",
    "    except_media_list = ['매일경제', '매일', '경제', 'maeil', 'MK', 'mk',\n",
    "                         '아시아경제', '아시아', 'Asia', 'ASIA', 'asia',\n",
    "                         '삼프로TV', '삼프로', 'TV',\n",
    "                         '슈카월드', '슈카', '월드'\n",
    "                         '한국경제TV', '한국']\n",
    "    for word in [except_media_list]:\n",
    "        stopwords.append(word)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #### 2. Preprocessing\n",
    "    '''감성 어휘 사전 : negative / positive\n",
    "       뉴스 데이터 : samsung / hyundai / lg / sk\n",
    "       주식 데이터 : stock_samsung / stock_hyundai / stock_lg / stock_sk\n",
    "       공휴일 데이터 : holidays'''\n",
    "    \n",
    "    \n",
    "    ### 1) 뉴스 데이터 날짜 조정\n",
    "    \n",
    "    ## 1-1)업로드 시각 컬럼 추가\n",
    "    for i in range(len(corp_list)):\n",
    "        globals()[corp_list[i]]['time'] = globals()[corp_list[i]]['datetime'].str[-2:]\n",
    "    \n",
    "    ## 1-2) 전일 15시 ~ 금일 15시로 날짜 조정\n",
    "    after_market = ['15', '16', '17', '18', '19', '20', '21', '22', '23']\n",
    "\n",
    "    for i in range(len(corp_list)):\n",
    "        for j in range(len(globals()[corp_list[i]]['time'])):\n",
    "            if globals()[corp_list[i]]['time'][j] in after_market:\n",
    "                globals()[corp_list[i]]['date'][j] += datetime.timedelta(1)\n",
    "            else:\n",
    "                pass\n",
    "    \n",
    "    ## 1-3) 텍스트 전처리\n",
    "    # \\n, \\t, \\r 제거\n",
    "    for i in range(len(corp_list)):\n",
    "        for j in range(len(globals()[corp_list[i]]['text'])):\n",
    "            globals()[corp_list[i]]['text'][j] = globals()[corp_list[i]]['text'][j].replace('[\\n|\\t|\\r]', '')\n",
    "#     # text 컬럼의 Stop Words 제거\n",
    "#     for i in range(len(corp_list)):\n",
    "#         globals()[corp_list[i]]['except_stopwords'] = 0\n",
    "#         for j in range(len(globals()[corp_list[i]]['text'])):            \n",
    "#             hangeul = re.compile('[^ ㄱ-ㅣ 가-힣]')                         # 정규 표현식  → 한글 추출 규칙 : 띄어쓰기(1개)를 포함한 한글\n",
    "#             result = hangeul.sub('', globals()[corp_list[i]]['text'][j])   # 위에 설정한 hangeul 규칙을 text에 적용\n",
    "#             okt = Okt()                                                    # 형태소 추출\n",
    "#             nouns = okt.nouns(result)\n",
    "#             nouns = [x for x in nouns if len(x) > 1]                       # 한 글자 키워드 제거\n",
    "#             nouns = [x for x in nouns if x not in stopwords]               # 불용어 제거\n",
    "            \n",
    "#             corpus = \" \".join(nouns)                                       # List를 String으로 변환\n",
    "#             globals()[corp_list[i]]['except_stopwords'][j] = corpus\n",
    "    \n",
    "        \n",
    "    ### 2) 주말 및 공휴일 제외\n",
    "    \n",
    "    ## 2-1) 주말 및 공휴일만 추출\n",
    "    market_closed = globals()['holidays'][globals()['holidays']['holiday']==\"O\"].reset_index(drop=True)\n",
    "    \n",
    "    ## 2-3) 휴장일 List 생성\n",
    "    market_closed_list = list(market_closed['date'])\n",
    "    \n",
    "    ## 2-4) iteration limit 조정\n",
    "    limit_number = 15000\n",
    "    sys.setrecursionlimit(limit_number)\n",
    "    \n",
    "    ## 2-5) 휴장일 제외 함수 적용\n",
    "    # 주말 및 공휴일 제외 함수\n",
    "#     def stock_market_closed(df):\n",
    "#         for i in range(len(df['date'])):\n",
    "#             if df['date'][i] in market_closed_list:\n",
    "#                 df['date'][i] += datetime.timedelta(1)\n",
    "#                 stock_market_closed(df)\n",
    "#             else:\n",
    "#                 pass\n",
    "#         return df\n",
    "    \n",
    "#     for i in range(len(corp_list)):\n",
    "#         stock_market_closed(globals()[corp_list[i]])\n",
    "    for i in range(len(corp_list)):\n",
    "        while len(globals()[corp_list[i]][globals()[corp_list[i]]['date'].isin(market_closed_list)]['date']) != 0:\n",
    "            for j in globals()[corp_list[i]][globals()[corp_list[i]]['date'].isin(market_closed_list)]['date'].index:\n",
    "                globals()[corp_list[i]]['date'][j] += datetime.timedelta(1)\n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "    #### 3. Sentiment Analysis\n",
    "    \n",
    "    \n",
    "#     ### 1) 종목별 긍부정 Score 계산\n",
    "#     for i in range(len(corp_list)):\n",
    "#         globals()[corp_list[i]]['score'] = 0\n",
    "#         tokenizer = Okt()\n",
    "\n",
    "#         for x in range(len(globals()[corp_list[i]]['date'])):\n",
    "#             score = 0\n",
    "#             num = tokenizer.nouns(globals()[corp_list[i]]['text'][x])\n",
    "#             for y in num:\n",
    "#                 # KOSELF 감성 어휘 사전\n",
    "#                 if y in positive:\n",
    "#                     score += 1\n",
    "#                 elif y in negative:\n",
    "#                     score -= 1\n",
    "#                 else:\n",
    "#                     score = score\n",
    "\n",
    "#             globals()[corp_list[i]]['score'][x] = score\n",
    "    \n",
    "    \n",
    "    ### 2) 주식가격 데이터와 결합\n",
    "    corp_label_list = []\n",
    "    for i in range(len(corp_list)):\n",
    "        \n",
    "        ## 2-1) 결합\n",
    "        globals()[corp_list[i] + '_label'] = pd.merge(globals()[corp_list[i]], globals()['stock_' + corp_list[i]], how='left', left_on='date', right_on='Date')\n",
    "        globals()[corp_list[i] + '_label'].drop('Date', axis=1, inplace=True)\n",
    "        \n",
    "        ## 2-2) UpDown과 Extremely_Changed(Change 상하위 5%) 컬럼 생성\n",
    "        # 주식 매매 수수료 평균 : 0.1% 정도(?) → 0을 추가해도 1, -1만 나옴\n",
    "        globals()[corp_list[i] + '_label']['UpDown'] = np.where((globals()[corp_list[i] + '_label']['Close']*globals()[corp_list[i] + '_label']['Change'])>(globals()[corp_list[i] + '_label']['Close']*0.001), 1,\n",
    "                                                                np.where((globals()[corp_list[i] + '_label']['Close']*globals()[corp_list[i] + '_label']['Change'])<(globals()[corp_list[i] + '_label']['Close']*0.001), -1, 0))\n",
    "#         # 단순히 Change가 (+), 0, (-)인지에 따라 각각 1, 0, -1\n",
    "#         globals()[corp_list[i] + '_label']['UpDown'] = np.where(globals()[corp_list[i] + '_label']['Change']>0, 1,\n",
    "#                                                                 np.where(globals()[corp_list[i] + '_label']['Change']<0, -1, 0))\n",
    "        globals()[corp_list[i] + '_label']['Extremely_Changed'] = np.where((globals()[corp_list[i] + '_label']['Change']>globals()[corp_list[i] + '_label']['Change'].quantile(.95)) & (globals()[corp_list[i] + '_label']['Change']>0), 1,\n",
    "                                                                            np.where((globals()[corp_list[i] + '_label']['Change']<globals()[corp_list[i] + '_label']['Change'].quantile(.05)) & (globals()[corp_list[i] + '_label']['Change']<0), -1, 0))\n",
    "        \n",
    "        ## 2-3) List에 추가\n",
    "        corp_label_list.append(globals()[corp_list[i] + '_label'])\n",
    "        \n",
    "        ## 2-4) text 컬럼의 NaN 제거\n",
    "        globals()[corp_list[i] + '_label'].dropna(axis=0, inplace=True)\n",
    "    \n",
    "    \n",
    "    ### 3) Tokenization 컬럼 추가\n",
    "    for i in range(len(corp_list)):\n",
    "        globals()[corp_list[i] + '_label']['Tokenization'] = 0\n",
    "        rows = globals()[corp_list[i] + '_label'].shape[0]\n",
    "        for j in range(rows):\n",
    "            hangeul = re.compile('[^ ㄱ-ㅣ 가-힣]')                                    # 정규 표현식 → 한글 추출 규칙 : 띄어쓰기(1개)를 포함한 한글\n",
    "            result = hangeul.sub('', globals()[corp_list[i] + '_label']['text'][j])   # 위에 설정한 hangeul 규칙을 text에 적용\n",
    "            okt = Okt()                                                               # 형태소 추출\n",
    "            nouns = okt.nouns(globals()[corp_list[i] + '_label']['text'][j])\n",
    "            nouns = [x for x in nouns if len(x) > 1]                                  # 한 글자 키워드 제거\n",
    "            nouns = [x for x in nouns if x not in stopwords]                          # 불용어 제거\n",
    "            \n",
    "            corpus = \" \".join(nouns)                                                  # List를 String으로 변환\n",
    "            globals()[corp_list[i] + '_label']['Tokenization'][j] = corpus\n",
    "        \n",
    "    \n",
    "    ### 4) 전체 종목 DataFrame 통합\n",
    "    globals()['total_label'] = pd.concat(corp_label_list, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4901ab3-b4b4-40ee-abb1-264034db5621",
   "metadata": {},
   "source": [
    "## **매일경제**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f785f9d-c17b-4de0-a358-61bacbe5a6d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "***매체명 입력(매일경제/아시아경제/삼프로TV/슈카월드/한국경제TV) : 매일경제\n",
      "***시작 날짜(YYYY-MM-DD) : 2021-01-01\n",
      "***종료 날짜(YYYY-MM-DD) : 2021-09-15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('maeil_news_craw', '2021-01-01', '2021-09-15')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arguments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13ff2448-3698-4a5c-9b4b-dbce15a29177",
   "metadata": {},
   "outputs": [],
   "source": [
    "media_stock_prediction(craw_media, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3143d421-4a12-41be-a6bb-357a401ac387",
   "metadata": {},
   "outputs": [],
   "source": [
    "corp_list = ['samsung', 'hyundai', 'lg', 'sk', 'celltrion']\n",
    "for i in range(len(corp_list)):\n",
    "    globals()[corp_list[i] + '_label'].to_csv('../../../../Code/Data/Test/Stock-Year/2021_maeil_{0}.csv'.format(corp_list[i]), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8333bfe3-c662-4d86-b656-43625c49d99f",
   "metadata": {},
   "source": [
    "## **아시아경제**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7b0fc81-6a43-4598-8024-83d444880cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "***매체명 입력(매일경제/아시아경제/삼프로TV/슈카월드/한국경제TV) : 아시아경제\n",
      "***시작 날짜(YYYY-MM-DD) : 2021-01-01\n",
      "***종료 날짜(YYYY-MM-DD) : 2021-09-15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('asia_news_craw', '2021-01-01', '2021-09-15')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arguments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfc8a3b8-d0eb-4e0b-807c-2a6b8a009648",
   "metadata": {},
   "outputs": [],
   "source": [
    "media_stock_prediction(craw_media, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d0c65cb-79d0-4f24-b276-3276a0356694",
   "metadata": {},
   "outputs": [],
   "source": [
    "corp_list = ['samsung', 'hyundai', 'lg', 'sk', 'celltrion']\n",
    "for i in range(len(corp_list)):\n",
    "    globals()[corp_list[i] + '_label'].to_csv('../../../../Code/Data/Test/Stock-Year/2021_asia_{0}.csv'.format(corp_list[i]), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e12d862-71c1-499b-b4c4-04328f76ee5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python Multi",
   "language": "python",
   "name": "multi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
