{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57ac1827-4ba4-44f1-a6a7-56e71f69502f",
   "metadata": {},
   "source": [
    "# **Stop Words & Tokenizing(2019)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b017417-8ff2-4c14-a288-3c3e1dbd2cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# DB 연결\n",
    "# !pip install pymysql\n",
    "import pymysql\n",
    "\n",
    "# DB에 저장\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# 실시간 주식가격 데이터\n",
    "# !pip install finance-datareader\n",
    "import FinanceDataReader as fdr\n",
    "\n",
    "# 텍스트 분석\n",
    "# 1) JAVA 설치, 2) Python 버전과 맞는 JPype1-py3 설치, 3) !pip install konlpy, 4) 설치 경로에서 jvm.py 파일 코드 67번 줄 주석 처리 \n",
    "from konlpy.tag import Okt\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import re\n",
    "\n",
    "# 모델 학습 및 평가\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# 모델 저장 및 로드\n",
    "import joblib\n",
    "\n",
    "# 기타\n",
    "import datetime\n",
    "from collections import Counter\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c09414c-aaef-404c-8a45-9eb391a0aa3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "maeil = pd.read_csv('../../../../Code/Data/2019_maeil.csv')\n",
    "asia = pd.read_csv('../../../../Code/Data/2019_asia.csv')\n",
    "\n",
    "media_list = [maeil, asia]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a032820-9cc4-4cd4-b6e9-3f7bc5e33ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop Words List에 각 매체명 추가\n",
    "stopwords = pd.read_csv(\"https://raw.githubusercontent.com/yoonkt200/FastCampusDataset/master/korean_stopwords.txt\")\n",
    "media_list = ['매일경제', '아시아경제', '삼프로TV', '슈카월드', '한국경제TV']\n",
    "for word in [media_list]:\n",
    "    stopwords.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30ab1c91-a66a-4ead-9989-cfe8439b994e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-5e7dbca4a457>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmedia_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mmedia_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'except_stopwords'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmedia_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mhangeul\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'[^ ㄱ-ㅣ 가-힣]'\u001b[0m\u001b[1;33m)\u001b[0m               \u001b[1;31m# 정규 표현식  → 한글 추출 규칙 : 띄어쓰기(1개)를 포함한 한글\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhangeul\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmedia_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m# 위에 설정한 hangeul 규칙을 text에 적용\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'str' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "for i in range(len(media_list)):\n",
    "    media_list[i]['except_stopwords'] = 0\n",
    "    for j in range(len(media_list[i]['text'])):\n",
    "        hangeul = re.compile('[^ ㄱ-ㅣ 가-힣]')               # 정규 표현식  → 한글 추출 규칙 : 띄어쓰기(1개)를 포함한 한글\n",
    "        result = hangeul.sub('', media_list[i]['text'][j])   # 위에 설정한 hangeul 규칙을 text에 적용\n",
    "        okt = Okt()                                          # 형태소 추출\n",
    "        nouns = okt.nouns(result)\n",
    "        nouns = [x for x in nouns if len(x) > 1]             # 한 글자 키워드 제거\n",
    "        nouns = [x for x in nouns if x not in stopwords]     # 불용어 제거\n",
    "        \n",
    "        corpus = \" \".join(nouns)                             # List를 String으로 변환\n",
    "        media_list[i]['except_stopwords'][j] = corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44edd08a-777e-4b62-b223-91acbec8461c",
   "metadata": {},
   "outputs": [],
   "source": [
    "maeil.to_csv('../../../../Code/Data/Test/2019_maeil.csv', index=False)\n",
    "asia.to_csv('../../../../Code/Data/Test/2019_asia.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fdc7f4-7915-49a5-b2b2-944a1871f02b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python Multi",
   "language": "python",
   "name": "multi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
